# -*- coding: utf-8 -*-
"""Real estate project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rCZgpqbOyr6Fj01Mp3ZdIJeUcdAcBrPI
"""

import pandas as pd

melbourne_data = pd.read_csv('melb_data.csv') #This line reads the data from the csv file of the housing project
melbourne_data.head() #This line shows how the data is structured in the dataframe of table.
melbourne_data.describe() #This line of code describe how the data is distributed statistically in the table.
melbourne_data = melbourne_data.dropna(axis=0) #This code remove all the missing values in the dataset

"""## **Interpreting Data Description**
* The count row tells about the number of rows that are not empty in the the dataset. \
* The mean row tells us about the mean/average of each column in the dataset. \
* The std row tells us about the standard deviation of the dataset on each column. \
* The min, max 25\%, 50\%, 75\% rows tells about the minimum to maximum with different percentile in between found in each column of the dataset. \

### **Data manupulation for feature engineering of the decision tree model**
"""

#melbourne_data = melbourne_data.dropna(axis=0) #This line of code drop values that have values that are not valid or have zero values.
melbourne_data.columns #Thid code shows me the column names which are called features to be use in the machine learning decision tree model
melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea','YearBuilt', 'Lattitude', 'Longtitude'] #This line of code chooses tye features I want to use in the model to predict the target feature
X = melbourne_data[melbourne_features] #This only takes the requires features in the whole dataset
y = melbourne_data.Price

"""### **Quickly looking at the dataset statistical appearance and the first few row in the table**"""

X.head() #This code looks the first row of the dataset with selected features
X.describe() #This code gives us the statistical overview of the data feature data

"""### **Decision tree model**"""

from sklearn.tree import DecisionTreeRegressor #This code imports the sklearn library to use the Decision tree model

melbourne_model = DecisionTreeRegressor(criterion="squared_error",max_depth = 3,random_state=98) #This code creates the model.
model_fit = melbourne_model.fit(X,y) #This line of code fits the model in the data we have given the features.
model_predictions =melbourne_model.predict(X) #This code checks the predictions in our dataset.

"""### **Model Validation** 
To check if our model gets good predictions we have to validate the model using simple Mean Root Square function.
"""

from sklearn.metrics import mean_absolute_error #This code imports the library that will be used to check the error of our model for validation
mean_absolute_error(y,model_predictions)

"""### **Split data**
The above method is not so accurate because it validates the model from the train that which is problem. This naive method will give wrong predictions so we need to split the data into two dataset (training and validation), this will ensure that we fit the data from new dataset the model have never seen. Decision tree function is created.
"""

from sklearn.model_selection import train_test_split

train_X,val_X,train_y,val_y = train_test_split(X,y,random_state=98) #This code splits the data into two dataset traing and validation data
def ML_Decision_Tree(max_leaf_nodes=None,max_depth=None):
  """Thsis function creates a simple decision tree with arguments 
  max_leaf_nodes as 'None' if not specified and max depth as 'None' if not specified"""
  melbourne_model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes,random_state=98,max_depth = max_depth) #This code creates the model.
  model_fit = melbourne_model.fit(train_X,train_y) #This line of code fits the model in the data we have given the features.
  model_predictions =melbourne_model.predict(val_X) #This code checks the predictions in our dataset.
  return print('\n Max leaf nodes: {} \n Max depth: {} \n Mean root square: {}'.format(max_leaf_nodes,max_depth,mean_absolute_error(val_y,model_predictions)))

y = [5,50,500,5000,50000,None]
best_tree = list()
for max_leaf_nodes in y:
  ML_Decision_Tree(max_leaf_nodes,max_depth=max_leaf_nodes)

from sklearn.ensemble import RandomForestRegressor

forest_model = RandomForestRegressor(random_state=1)
forest_model.fit(train_X, train_y)
melb_preds = forest_model.predict(val_X)
print(mean_absolute_error(val_y, melb_preds))

"""### **Visualising the decision tree with depth 3**"""

import graphviz #This code import the library to visualise the decision tree 
from sklearn import tree #This code imports the tree library
dot_data = tree.export_graphviz(melbourne_model, out_file=None, 
                                feature_names=melbourne_features,
                                filled=True)#This code uses the tree library to create the visual tree

# Draw graph
graph = graphviz.Source(dot_data, format="png") #This code plots the tree using the graphviz
graph #This code excute the visual tree